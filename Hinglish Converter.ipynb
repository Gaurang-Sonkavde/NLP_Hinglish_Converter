{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfa93b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.500\n",
      "             2          -0.69315        0.500\n",
      "             3          -0.69315        0.500\n",
      "             4          -0.69315        0.500\n",
      "             5          -0.69315        0.500\n",
      "             6          -0.69315        0.500\n",
      "             7          -0.69315        0.500\n",
      "             8          -0.69315        0.500\n",
      "             9          -0.69315        0.500\n",
      "            10          -0.69315        0.500\n",
      "            11          -0.69315        0.500\n",
      "            12          -0.69315        0.500\n",
      "            13          -0.69315        0.500\n",
      "            14          -0.69315        0.500\n",
      "            15          -0.69315        0.500\n",
      "            16          -0.69315        0.500\n",
      "            17          -0.69315        0.500\n",
      "            18          -0.69315        0.500\n",
      "            19          -0.69315        0.500\n",
      "            20          -0.69315        0.500\n",
      "            21          -0.69315        0.500\n",
      "            22          -0.69315        0.500\n",
      "            23          -0.69315        0.500\n",
      "            24          -0.69315        0.500\n",
      "            25          -0.69315        0.500\n",
      "            26          -0.69315        0.500\n",
      "            27          -0.69315        0.500\n",
      "            28          -0.69315        0.500\n",
      "            29          -0.69315        0.500\n",
      "            30          -0.69315        0.500\n",
      "            31          -0.69315        0.500\n",
      "            32          -0.69315        0.500\n",
      "            33          -0.69315        0.500\n",
      "            34          -0.69315        0.500\n",
      "            35          -0.69315        0.500\n",
      "            36          -0.69315        0.500\n",
      "            37          -0.69315        0.500\n",
      "            38          -0.69315        0.500\n",
      "            39          -0.69315        0.500\n",
      "            40          -0.69315        0.500\n",
      "            41          -0.69315        0.500\n",
      "            42          -0.69315        0.500\n",
      "            43          -0.69315        0.500\n",
      "            44          -0.69315        0.500\n",
      "            45          -0.69315        0.500\n",
      "            46          -0.69315        0.500\n",
      "            47          -0.69315        0.500\n",
      "            48          -0.69315        0.500\n",
      "            49          -0.69315        0.500\n",
      "            50          -0.69315        0.500\n",
      "            51          -0.69315        0.500\n",
      "            52          -0.69315        0.500\n",
      "            53          -0.69315        0.500\n",
      "            54          -0.69315        0.500\n",
      "            55          -0.69315        0.500\n",
      "            56          -0.69315        0.500\n",
      "            57          -0.69315        0.500\n",
      "            58          -0.69315        0.500\n",
      "            59          -0.69315        0.500\n",
      "            60          -0.69315        0.500\n",
      "            61          -0.69315        0.500\n",
      "            62          -0.69315        0.500\n",
      "            63          -0.69315        0.500\n",
      "            64          -0.69315        0.500\n",
      "            65          -0.69315        0.500\n",
      "            66          -0.69315        0.500\n",
      "            67          -0.69315        0.500\n",
      "            68          -0.69315        0.500\n",
      "            69          -0.69315        0.500\n",
      "            70          -0.69315        0.500\n",
      "            71          -0.69315        0.500\n",
      "            72          -0.69315        0.500\n",
      "            73          -0.69315        0.500\n",
      "            74          -0.69315        0.500\n",
      "            75          -0.69315        0.500\n",
      "            76          -0.69315        0.500\n",
      "            77          -0.69315        0.500\n",
      "            78          -0.69315        0.500\n",
      "            79          -0.69315        0.500\n",
      "            80          -0.69315        0.500\n",
      "            81          -0.69315        0.500\n",
      "            82          -0.69315        0.500\n",
      "            83          -0.69315        0.500\n",
      "            84          -0.69315        0.500\n",
      "            85          -0.69315        0.500\n",
      "            86          -0.69315        0.500\n",
      "            87          -0.69315        0.500\n",
      "            88          -0.69315        0.500\n",
      "            89          -0.69315        0.500\n",
      "            90          -0.69315        0.500\n",
      "            91          -0.69315        0.500\n",
      "            92          -0.69315        0.500\n",
      "            93          -0.69315        0.500\n",
      "            94          -0.69315        0.500\n",
      "            95          -0.69315        0.500\n",
      "            96          -0.69315        0.500\n",
      "            97          -0.69315        0.500\n",
      "            98          -0.69315        0.500\n",
      "            99          -0.69315        0.500\n",
      "         Final          -0.69315        0.500\n",
      "NaiveBayesClassifier - Accuracy: 0.50, Predicted Sentiment: pos\n",
      "DecisionTreeClassifier - Accuracy: 0.50, Predicted Sentiment: pos\n",
      "MaxentClassifier - Accuracy: 0.50, Predicted Sentiment: pos\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from googletrans import Translator\n",
    "from nltk import NaiveBayesClassifier, DecisionTreeClassifier, MaxentClassifier\n",
    "from nltk.classify import apply_features\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "# Function to preprocess the input text\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    translator = Translator(service_urls=['translate.google.co.in'])\n",
    "    \n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    text = translator.translate(text, src=\"hi\", dest=\"en\").text\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = \" \".join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to extract features from the preprocessed text\n",
    "def extract_features(text, adjectives):\n",
    "    return {word: True for word in text.split() if word in adjectives}\n",
    "\n",
    "# Function to train multiple classifiers\n",
    "def train_classifiers(pos_data, neg_data, adjectives):\n",
    "    classifiers = [\n",
    "        (NaiveBayesClassifier, \"NaiveBayesClassifier\"),\n",
    "        (DecisionTreeClassifier, \"DecisionTreeClassifier\"),\n",
    "        (MaxentClassifier, \"MaxentClassifier\")\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for classifier_type, classifier_name in classifiers:\n",
    "        pos_features = [(extract_features(preprocess(text), adjectives), 'pos') for text in pos_data]\n",
    "        neg_features = [(extract_features(preprocess(text), adjectives), 'neg') for text in neg_data]\n",
    "        \n",
    "        train_data = pos_features + neg_features\n",
    "        classifier = classifier_type.train(train_data)\n",
    "        \n",
    "        acc = accuracy(classifier, train_data)\n",
    "        results.append((classifier_name, acc, classifier))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "positive_data = [\"This app is great!\", \"I love the new features.\", \"Amazing experience.\"]\n",
    "negative_data = [\"The app crashes frequently.\", \"Disappointed with the update.\", \"Worst app ever.\"]\n",
    "\n",
    "adjectives = [\"good\", \"bad\", \"amazing\", \"worst\"]  # Add your list of adjectives\n",
    "\n",
    "classifiers_results = train_classifiers(positive_data, negative_data, adjectives)\n",
    "\n",
    "# Test the classifiers with sample text\n",
    "test_text = \"The latest update is fantastic!\"\n",
    "\n",
    "for classifier_name, acc, classifier in classifiers_results:\n",
    "    # Preprocess the test text\n",
    "    preprocessed_text = preprocess(test_text)\n",
    "\n",
    "    # Extract features from the preprocessed text\n",
    "    test_features = extract_features(preprocessed_text, adjectives)\n",
    "\n",
    "    # Classify the sentiment using the trained classifier\n",
    "    predicted_sentiment = classifier.classify(test_features)\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"{classifier_name} - Accuracy: {acc:.2f}, Predicted Sentiment: {predicted_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d0eb94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>NaiveBayesClassifier</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>MaxentClassifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>preprocessed_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghatiya app hai.</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.625</td>\n",
       "      <td>cheap app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service user-friendly nahi hai.</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.625</td>\n",
       "      <td>Service userfriendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bohot badiya app hai</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.625</td>\n",
       "      <td>good app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The latest update is disappointing.</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.625</td>\n",
       "      <td>latest update disappointing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              comments NaiveBayesClassifier  \\\n",
       "0                     Ghatiya app hai.                  pos   \n",
       "1      service user-friendly nahi hai.                  pos   \n",
       "2                 Bohot badiya app hai                  neg   \n",
       "3  The latest update is disappointing.                  pos   \n",
       "\n",
       "  DecisionTreeClassifier MaxentClassifier accuracy  \\\n",
       "0                    pos              pos    0.625   \n",
       "1                    pos              pos    0.625   \n",
       "2                    neg              neg    0.625   \n",
       "3                    pos              pos    0.625   \n",
       "\n",
       "          preprocessed_comment  \n",
       "0                    cheap app  \n",
       "1         Service userfriendly  \n",
       "2                     good app  \n",
       "3  latest update disappointing  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'comments': [\n",
    "    \"Ghatiya app hai.\",\n",
    "    \"service user-friendly nahi hai.\",\n",
    "    \"Bohot badiya app hai\",\n",
    "    \"The latest update is disappointing.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Create new columns to store the results\n",
    "classifiers_names = [classifier_name for classifier_name, _, _ in classifiers_results]\n",
    "df[classifiers_names + ['accuracy', 'preprocessed_comment']] = \"\"\n",
    "\n",
    "# Test the classifiers with the comments column in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    comment = row['comments']\n",
    "    \n",
    "    results_for_comment = []\n",
    "\n",
    "    for classifier_name, acc, classifier in classifiers_results:\n",
    "        # Preprocess the comment\n",
    "        preprocessed_comment = preprocess(comment)\n",
    "\n",
    "        # Extract features from the preprocessed comment\n",
    "        comment_features = extract_features(preprocessed_comment, adjectives)\n",
    "\n",
    "        # Classify the sentiment using the trained classifier\n",
    "        predicted_sentiment = classifier.classify(comment_features)\n",
    "\n",
    "        # Store the results in a tuple\n",
    "        results_for_comment.append((classifier_name, acc, predicted_sentiment))\n",
    "\n",
    "    # Sort the results by accuracy in descending order\n",
    "    results_for_comment.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Store the results in the DataFrame columns\n",
    "    for result in results_for_comment:\n",
    "        classifier_name, acc, predicted_sentiment = result\n",
    "        df.at[index, classifier_name] = predicted_sentiment\n",
    "\n",
    "    # Store the highest accuracy result in the DataFrame columns\n",
    "    df.at[index, 'accuracy'] = results_for_comment[0][1]\n",
    "    df.at[index, 'preprocessed_comment'] = preprocessed_comment\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee5b3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7ec2440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>translated_comment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bekar app hai.</td>\n",
       "      <td>Is a useless app.</td>\n",
       "      <td>-0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aur better ho sakta tha</td>\n",
       "      <td>And could be better</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bohot badiya app hai</td>\n",
       "      <td>It is very good app</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The latest update is disappointing.</td>\n",
       "      <td>The latest update is disappointing.</td>\n",
       "      <td>-0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fraud app banaya hai</td>\n",
       "      <td>Fraud app is created</td>\n",
       "      <td>-0.4215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              comments                   translated_comment  \\\n",
       "0                       Bekar app hai.                    Is a useless app.   \n",
       "1              Aur better ho sakta tha                  And could be better   \n",
       "2                 Bohot badiya app hai                  It is very good app   \n",
       "3  The latest update is disappointing.  The latest update is disappointing.   \n",
       "4                Fraud app banaya hai                  Fraud app is created   \n",
       "\n",
       "  sentiment_score  \n",
       "0         -0.4215  \n",
       "1          0.4404  \n",
       "2          0.4404  \n",
       "3         -0.4939  \n",
       "4         -0.4215  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from googletrans import Translator\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Function to preprocess the input text\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    translator = Translator(service_urls=['translate.google.co.in'])\n",
    "    \n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    text = translator.translate(text, src=\"hi\", dest=\"en\").text\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = \" \".join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to translate Hinglish comments to English\n",
    "def translate_to_english(comment):\n",
    "    translator = Translator(service_urls=['translate.google.co.in'])\n",
    "    return translator.translate(comment, src=\"hi\", dest=\"en\").text\n",
    "\n",
    "# Sample DataFrame with Hinglish comments\n",
    "df = pd.DataFrame({\n",
    "    'comments': [\n",
    "        \"Bekar app hai.\",\n",
    "        \"Aur better ho sakta tha\",\n",
    "        \"Bohot badiya app hai\",\n",
    "        \"The latest update is disappointing.\",\n",
    "        \"Fraud app banaya hai \"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Create new columns to store the results\n",
    "df['translated_comment'] = \"\"\n",
    "df['sentiment_score'] = \"\"\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Translate Hinglish comments to English and analyze sentiment\n",
    "for index, row in df.iterrows():\n",
    "    hinglish_comment = row['comments']\n",
    "\n",
    "    # Translate Hinglish comment to English\n",
    "    english_comment = translate_to_english(hinglish_comment)\n",
    "    df.at[index, 'translated_comment'] = english_comment\n",
    "\n",
    "    # Preprocess the translated comment\n",
    "    preprocessed_comment = preprocess(english_comment)\n",
    "\n",
    "    # Analyze sentiment using SentimentIntensityAnalyzer\n",
    "    sentiment_score = sia.polarity_scores(preprocessed_comment)['compound']\n",
    "\n",
    "    # Store the sentiment score in the DataFrame column\n",
    "    df.at[index, 'sentiment_score'] = sentiment_score\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b13877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0721d1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>translated_comment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bekar app hai.</td>\n",
       "      <td>Is a useless app.</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aur better ho sakta tha</td>\n",
       "      <td>And could be better</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bohot badiya app hai</td>\n",
       "      <td>It is very good app</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The latest update is disappointing.</td>\n",
       "      <td>The latest update is disappointing.</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fraud app banaya hai</td>\n",
       "      <td>Fraud app is created</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              comments                   translated_comment  \\\n",
       "0                       Bekar app hai.                    Is a useless app.   \n",
       "1              Aur better ho sakta tha                  And could be better   \n",
       "2                 Bohot badiya app hai                  It is very good app   \n",
       "3  The latest update is disappointing.  The latest update is disappointing.   \n",
       "4                Fraud app banaya hai                  Fraud app is created   \n",
       "\n",
       "  sentiment_score sentiment  \n",
       "0         -0.4215  negative  \n",
       "1          0.4404  positive  \n",
       "2          0.4404  positive  \n",
       "3         -0.4939  negative  \n",
       "4         -0.4215  negative  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from googletrans import Translator\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Function to preprocess the input text\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    translator = Translator(service_urls=['translate.google.co.in'])\n",
    "    \n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    text = translator.translate(text, src=\"hi\", dest=\"en\").text\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = \" \".join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to translate Hinglish comments to English\n",
    "def translate_to_english(comment):\n",
    "    translator = Translator(service_urls=['translate.google.co.in'])\n",
    "    return translator.translate(comment, src=\"hi\", dest=\"en\").text\n",
    "\n",
    "# Function to categorize sentiment as positive, negative, or neutral\n",
    "def categorize_sentiment(score):\n",
    "    if score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Sample DataFrame with Hinglish comments\n",
    "df = pd.DataFrame({\n",
    "    'comments': [\n",
    "        \"Bekar app hai.\",\n",
    "        \"Aur better ho sakta tha\",\n",
    "        \"Bohot badiya app hai\",\n",
    "        \"The latest update is disappointing.\",\n",
    "        \"Fraud app banaya hai \"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Create new columns to store the results\n",
    "df['translated_comment'] = \"\"\n",
    "df['sentiment_score'] = \"\"\n",
    "df['sentiment'] = \"\"\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Translate Hinglish comments to English and analyze sentiment\n",
    "for index, row in df.iterrows():\n",
    "    hinglish_comment = row['comments']\n",
    "\n",
    "    # Translate Hinglish comment to English\n",
    "    english_comment = translate_to_english(hinglish_comment)\n",
    "    df.at[index, 'translated_comment'] = english_comment\n",
    "\n",
    "    # Preprocess the translated comment\n",
    "    preprocessed_comment = preprocess(english_comment)\n",
    "\n",
    "    # Analyze sentiment using SentimentIntensityAnalyzer\n",
    "    sentiment_score = sia.polarity_scores(preprocessed_comment)['compound']\n",
    "    df.at[index, 'sentiment_score'] = sentiment_score\n",
    "\n",
    "    # Categorize sentiment\n",
    "    sentiment_category = categorize_sentiment(sentiment_score)\n",
    "    df.at[index, 'sentiment'] = sentiment_category\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a824f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
